{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 3. Градиентный спуск своими руками\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 05.10.2019\n",
    "\n",
    "Мягкий дедлайн: 07:59MSK 14.10.2019 (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 16.10.2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В данном задании необходимо реализовать обучение линейной регрессии с помощью различных вариантов градиентного спуска.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему Anytask. Инвайт можно найти на странице курса. Присылать необходимо ноутбук с выполненным заданием. \n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
    "\n",
    "**Оценка**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация градиентного спуска\n",
    "\n",
    "Реализуйте линейную регрессию с функцией потерь MSE, обучаемую с помощью:\n",
    "\n",
    "** Задание 1 (1 балл)** Градиентного спуска;\n",
    "\n",
    "** Задание 2 (1.5 балла)** Стохастического градиентного спуска;\n",
    "\n",
    "** Задание 3 (2.5 балла)** Метода Momentum.\n",
    "\n",
    "\n",
    "Во всех пунктах необходимо соблюдать следующие условия:\n",
    "\n",
    "* Все вычисления должны быть векторизованы;\n",
    "* Циклы средствами python допускается использовать только для итераций градиентного спуска;\n",
    "* В качестве критерия останова необходимо использовать (одновременно):\n",
    "\n",
    "    * проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$, задаваемого параметром `tolerance`);\n",
    "    * достижение максимального числа итераций (например, 10000, задаваемого параметром `max_iter`).\n",
    "* Чтобы проследить, что оптимизационный процесс действительно сходится, будем использовать атрибут класса `loss_history` — в нём после вызова метода `fit` должны содержаться значения функции потерь для всех итераций, начиная с первой (до совершения первого шага по антиградиенту);\n",
    "* Инициализировать веса можно случайным образом или нулевым вектором. \n",
    "\n",
    "\n",
    "Ниже приведён шаблон класса, который должен содержать код реализации каждого из методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LinearReg(BaseEstimator):\n",
    "    def __init__(self, gd_type='stochastic', \n",
    "                 tolerance=1e-4, max_iter=1000, w0=None,\n",
    "                 alpha=1e-3, eta=1e-2):\n",
    "        \"\"\"\n",
    "        gd_type: 'full' or 'stochastic' or 'momentum'\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d) - init weights\n",
    "        eta: learning rate\n",
    "        alpha: momentum coefficient\n",
    "        \"\"\"\n",
    "        self.gd_type = gd_type\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.eta = eta\n",
    "        self.h = 0 # for momentum method\n",
    "        self.loss_history = None # list of loss function values at each training iteration\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        X = X.values\n",
    "        y = y.values\n",
    "        self.loss_history = []\n",
    "        if not self.w0:\n",
    "            self.w0 = np.zeros(X.shape[1])\n",
    "        self.w = self.w0.copy()\n",
    "        \n",
    "        for step in range(1, self.max_iter):\n",
    "            last_w = self.w.copy()\n",
    "            self.w = self.calc_gradient(X, y, step)\n",
    "            self.loss_history.append(self.calc_loss(X, y))\n",
    "            if np.linalg.norm(last_w - self.w) < self.tolerance:\n",
    "                break\n",
    "        # print(step)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "\n",
    "        return np.dot(X, self.w)\n",
    "    \n",
    "    def calc_gradient(self, X, y, step):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d) (ell can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        step_size = self.eta/step\n",
    "        if self.gd_type == 'full':\n",
    "            result = self.w - 2 * step_size * np.dot(X.T, self.predict(X) - y) / y.shape[0]\n",
    "        elif self.gd_type == 'stochastic':\n",
    "            sample = np.random.randint(X.shape[0], size=10)\n",
    "            result = self.w - 2 * step_size * np.dot(X[sample].T, self.predict(X[sample]) - y[sample]) / y.shape[0]\n",
    "        elif self.gd_type == 'momentum':\n",
    "            self.h = self.alpha * self.h + 2 * step_size * np.dot(X.T, self.predict(X) - y) / y.shape[0]\n",
    "            result = self.w - self.h\n",
    "        return result\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (ell, d)\n",
    "        y: np.array of shape (ell)\n",
    "        ---\n",
    "        output: float \n",
    "        \"\"\" \n",
    "        return np.square(self.predict(X) - y).mean()\n",
    "    \n",
    "    def r2(self, X, y):\n",
    "        return 1 - np.square(self.predict(X) - y).sum() / np.square(y - y.mean()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание 4 (0 баллов)**. \n",
    "* Загрузите данные из домашнего задания 2 ([train.csv](https://www.kaggle.com/c/nyc-taxi-trip-duration/data));\n",
    "* Разбейте выборку на обучающую и тестовую в отношении 7:3 с random_seed=0;\n",
    "* Преобразуйте целевую переменную `trip_duration` как $\\hat{y} = \\log{(y + 1)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"../hw2/nyc-taxi-trip-duration/train.csv\")\n",
    "\n",
    "y = np.log1p(data['trip_duration'])\n",
    "data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "data['month'] = data['pickup_datetime'].dt.month\n",
    "data['hour'] = data['pickup_datetime'].dt.hour\n",
    "data['weekday'] = data['pickup_datetime'].dt.weekday\n",
    "X = data.drop(['trip_duration', 'id', 'pickup_datetime', 'store_and_fwd_flag', 'dropoff_datetime'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание 5 (3 балла)**. Обучите и провалидируйте модели на данных из предыдущего пункта, сравните качество между методами по метрикам MSE и $R^2$. Исследуйте влияние параметров `max_iter` и `alpha` на процесс оптимизации. Согласуется ли оно с вашими ожиданиями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_consts = [\n",
    "    {\n",
    "        'method': 'full',\n",
    "        'alpha': 1e-3,\n",
    "        'eta': 1e-3\n",
    "    }, \n",
    "    {\n",
    "        'method': 'stochastic',\n",
    "        'alpha': 1e-3,\n",
    "        'eta': 5\n",
    "    }, \n",
    "    {\n",
    "        'method': 'momentum',\n",
    "        'alpha': 1e-2,\n",
    "        'eta': 1e-3\n",
    "    }\n",
    "]\n",
    "consts = [\n",
    "    {\n",
    "        'method': 'full',\n",
    "        'alpha': [1e-3],\n",
    "        'eta': [1e-1, 1e-2, 1e-3],\n",
    "        'max_iter': [10, 20, 50]\n",
    "    }, \n",
    "    {\n",
    "        'method': 'stochastic',\n",
    "        'alpha': [1e-3],\n",
    "        'eta': [1, 5, 10],\n",
    "        'max_iter': [10, 20, 50]\n",
    "    }, \n",
    "    {\n",
    "        'method': 'momentum',\n",
    "        'alpha': [1e-1, 1e-2, 1e-3],\n",
    "        'eta': [1e-1, 1e-2, 1e-3],\n",
    "        'max_iter': [10, 20, 50]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.6295202708386565 ; for method = full\n",
      "R^2 = 0.000203236329585188 ; for method = full\n",
      "--------\n",
      "MSE = 0.6445186051835512 ; for method = stochastic\n",
      "R^2 = -0.023616943628235187 ; for method = stochastic\n",
      "--------\n",
      "MSE = 0.6295176590959156 ; for method = momentum\n",
      "R^2 = 0.00020738426899369333 ; for method = momentum\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for const in optimal_consts:\n",
    "    model = LinearReg(const['method'], eta=const['eta'], alpha=const['alpha'])\n",
    "    model.fit(X_train, y_train)\n",
    "    print('MSE = %s ; for method = %s' % (model.calc_loss(X_test, y_test), const['method']))\n",
    "    print('R^2 = %s ; for method = %s' % (model.r2(X_test, y_test), const['method']))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 6.304747848479411e+52 ; for method = full ; eta = 0.1 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 8.713687171967486e+98 ; for method = full ; eta = 0.1 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 8.593111901282663e+214 ; for method = full ; eta = 0.1 ; alpha = 0.001; max_iter = 50\n",
      "MSE = 4.750013952330409e+34 ; for method = full ; eta = 0.01 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 2.5950374014481782e+60 ; for method = full ; eta = 0.01 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 2.5105229681751396e+113 ; for method = full ; eta = 0.01 ; alpha = 0.001; max_iter = 50\n",
      "MSE = 1929618807949671.2 ; for method = full ; eta = 0.001 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 1811461295544736.8 ; for method = full ; eta = 0.001 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 0.6295202708386565 ; for method = full ; eta = 0.001 ; alpha = 0.001; max_iter = 50\n",
      "--------\n",
      "MSE = 7.78711612588528 ; for method = stochastic ; eta = 1 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 5.440788933700884 ; for method = stochastic ; eta = 1 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 4.058253035725273 ; for method = stochastic ; eta = 1 ; alpha = 0.001; max_iter = 50\n",
      "MSE = 0.634766108862451 ; for method = stochastic ; eta = 5 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 0.6371896044006528 ; for method = stochastic ; eta = 5 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 0.6297367276278841 ; for method = stochastic ; eta = 5 ; alpha = 0.001; max_iter = 50\n",
      "MSE = 0.6328844086983942 ; for method = stochastic ; eta = 10 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 0.6340185032578683 ; for method = stochastic ; eta = 10 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 0.6331319800940748 ; for method = stochastic ; eta = 10 ; alpha = 0.001; max_iter = 50\n",
      "--------\n",
      "MSE = 6.28553529663021e+52 ; for method = momentum ; eta = 0.1 ; alpha = 0.1; max_iter = 10\n",
      "MSE = 8.599668382994202e+98 ; for method = momentum ; eta = 0.1 ; alpha = 0.1; max_iter = 20\n",
      "MSE = 7.880813530996874e+214 ; for method = momentum ; eta = 0.1 ; alpha = 0.1; max_iter = 50\n",
      "MSE = 6.302824148248117e+52 ; for method = momentum ; eta = 0.1 ; alpha = 0.01; max_iter = 10\n",
      "MSE = 8.702219967547143e+98 ; for method = momentum ; eta = 0.1 ; alpha = 0.01; max_iter = 20\n",
      "MSE = 8.51911653713355e+214 ; for method = momentum ; eta = 0.1 ; alpha = 0.01; max_iter = 50\n",
      "MSE = 6.304555453984838e+52 ; for method = momentum ; eta = 0.1 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 8.712539795625735e+98 ; for method = momentum ; eta = 0.1 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 8.58568393628209e+214 ; for method = momentum ; eta = 0.1 ; alpha = 0.001; max_iter = 50\n",
      "MSE = 4.601688869036246e+34 ; for method = momentum ; eta = 0.01 ; alpha = 0.1; max_iter = 10\n",
      "MSE = 2.2489008884087434e+60 ; for method = momentum ; eta = 0.01 ; alpha = 0.1; max_iter = 20\n",
      "MSE = 8.440600461974663e+112 ; for method = momentum ; eta = 0.01 ; alpha = 0.1; max_iter = 50\n",
      "MSE = 4.7349852556488115e+34 ; for method = momentum ; eta = 0.01 ; alpha = 0.01; max_iter = 10\n",
      "MSE = 2.5582424182119614e+60 ; for method = momentum ; eta = 0.01 ; alpha = 0.01; max_iter = 20\n",
      "MSE = 2.253426254092998e+113 ; for method = momentum ; eta = 0.01 ; alpha = 0.01; max_iter = 50\n",
      "MSE = 4.748509103322276e+34 ; for method = momentum ; eta = 0.01 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 2.5913351279988894e+60 ; for method = momentum ; eta = 0.01 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 2.4835689581204244e+113 ; for method = momentum ; eta = 0.01 ; alpha = 0.001; max_iter = 50\n",
      "MSE = 1161152837209171.5 ; for method = momentum ; eta = 0.001 ; alpha = 0.1; max_iter = 10\n",
      "MSE = 83801879750.08817 ; for method = momentum ; eta = 0.001 ; alpha = 0.1; max_iter = 20\n",
      "MSE = 0.6295032018159148 ; for method = momentum ; eta = 0.001 ; alpha = 0.1; max_iter = 50\n",
      "MSE = 1836479199541204.5 ; for method = momentum ; eta = 0.001 ; alpha = 0.01; max_iter = 10\n",
      "MSE = 1078030317169217.5 ; for method = momentum ; eta = 0.001 ; alpha = 0.01; max_iter = 20\n",
      "MSE = 0.6295176590959156 ; for method = momentum ; eta = 0.001 ; alpha = 0.01; max_iter = 50\n",
      "MSE = 1920120171672270.8 ; for method = momentum ; eta = 0.001 ; alpha = 0.001; max_iter = 10\n",
      "MSE = 1722047073483257.5 ; for method = momentum ; eta = 0.001 ; alpha = 0.001; max_iter = 20\n",
      "MSE = 0.6295190247550636 ; for method = momentum ; eta = 0.001 ; alpha = 0.001; max_iter = 50\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for const in consts:\n",
    "    for eta in const['eta']:\n",
    "        for alpha in const['alpha']:\n",
    "            for max_iter in const['max_iter']:\n",
    "                model = LinearReg(const['method'], eta=eta, alpha=alpha, max_iter=max_iter)\n",
    "                model.fit(X_train, y_train)\n",
    "                print('MSE = %s ; for method = %s ; eta = %s ; alpha = %s; max_iter = %s' % (\n",
    "                    model.calc_loss(X_test, y_test), const['method'], eta, alpha, max_iter))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Параметр eta согласуется с ожиданием. Чем больше этот параметр, чем больше вероятность, что мы перескочим минимум и убежим на бесконечность. Аналогично с параметром alpha. Чем он больше, тем у нас будет больше инерция.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание 6 (2 балла)**. Постройте графики (на одной и той же картинке) зависимости величины функции потерь от номера итерации для полного, стохастического градиентного спусков, а также для полного градиентного спуска с методом Momentum. Сделайте выводы о скорости сходимости различных модификаций градиентного спуска.\n",
    "\n",
    "Не забывайте о том, что должны получиться *красивые* графики!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бонус "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание 7 (2 балла)**. Реализуйте линейную регрессию с функцией потерь MSE, обучаемую с помощью метода\n",
    "[Adam](https://arxiv.org/pdf/1412.6980.pdf) - добавьте при необходимости параметры в класс модели, повторите пункты 5 и 6 и сравните результаты. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание 8 (2 балла)**. Реализуйте линейную регрессию с функцией потерь\n",
    "$$ L(\\hat{y}, y) = log(cosh(\\hat{y} - y)),$$\n",
    "\n",
    "обучаемую с помощью градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание 9 (0.01 балла)**.  Вставьте картинку с вашим любимым мемом в этот Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
